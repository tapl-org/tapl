% Part of the TAPL project, under the Apache License v2.0 with LLVM
% Exceptions. See /LICENSE for license information.
% SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

\documentclass[11pt,letterpaper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,mathtools}

\begin{document}

\begin{center}
{\Large\bfseries $\theta$-Calculus: An Extension of the $\lambda$-Calculus}\\[4pt]
Orti Bazar (orti.bazar at gmail.com) --- February 21, 2026
\end{center}
\smallskip

%% ── Syntax & Meta-variables ──────────────────────────────────────────────

\setlength{\fboxsep}{6pt}
\noindent
\fbox{\begin{minipage}[t]{0.36\textwidth-2\fboxsep-2\fboxrule}
\vspace{0pt}
\begin{tabular*}{\linewidth}{@{}r@{\extracolsep{\fill}}c@{\extracolsep{\fill}}r@{}}
  & \textbf{Syntax} & \\[4pt]
$t ::=$ & & \textit{terms} \\[4pt]
        & $x$ & \textit{variable} \\[4pt]
        & $\lambda x.\,t$ & \textit{abstraction} \\[4pt]
        & $t\ t$ & \textit{application} \\[4pt]
        & $t{:}t$ & \textit{layering} \\[4pt]
        & $\theta.\,t$ & \textit{unlayering}
\end{tabular*}
\end{minipage}}%
\hfill
\fbox{\begin{minipage}[t]{0.58\textwidth-2\fboxsep-2\fboxrule}
\vspace{0pt}
\begin{tabular*}{\linewidth}{@{}r@{\extracolsep{\fill}}c@{\extracolsep{\fill}}r@{}}
  & \textbf{Meta-variables} & $t = g \mid h$ \\[4pt]
$g ::=$ & $x \mid \lambda x.\,g \mid g\ g \mid \theta.\,t$ & \textit{single layer} \\[4pt]
$h ::=$ & $\lambda x.\,h \mid g\ h \mid h\ g \mid h\ h \mid t{:}t$ & \textit{multi layer} \\[8pt]
  & \textbf{Single Layer} & $g = v \mid r$ \\[4pt]
$v ::=$ & $\lambda x.\,g$ & \textit{value} \\[4pt]
$r ::=$ & $x \mid g\ g \mid \theta.\,t$ & \textit{non-value} \\[8pt]
  & \textbf{Multi Layer} & $h = p \mid s$ \\[4pt]
$p ::=$ & $t{:}t$ & \textit{separated} \\[4pt]
$s ::=$ & $\lambda x.\,h \mid g\ h \mid h\ g \mid h\ h$ & \textit{separable}
\end{tabular*}
\end{minipage}}

\medskip

%% ── Evaluation & Separation ─────────────────────────────────────────────

\renewcommand{\arraystretch}{2.0}

\noindent
\fbox{\begin{minipage}[t]{0.47\textwidth-2\fboxsep-2\fboxrule}
\vspace{0pt}
\small
\begin{tabular*}{\linewidth}{@{}l@{\extracolsep{\fill}}c@{\extracolsep{\fill}}r@{}}
  & \textbf{Evaluation} & $\epsilon[t] \to t$ \\[4pt]
$x$
  & $\dfrac{\epsilon[x]}{x}$
  & \textsc{E-Var} \\[4pt]
$\lambda x.\,g$
  & $\dfrac{\epsilon[\lambda x.\,g]}{\lambda x.\,g}$
  & \textsc{E-Abs} \\[4pt]
$g\ g$
  & $r\ g \mid v\ r \mid v\ v$
  & \\[4pt]
  & $\dfrac{\epsilon[r\ g]}{\epsilon[r]\ g}$
  & \textsc{E-App1} \\[4pt]
  & $\dfrac{\epsilon[v\ r]}{v\ \epsilon[r]}$
  & \textsc{E-App2} \\[4pt]
  & $\dfrac{\epsilon[(\lambda x.\,g)\ v]}{[x \mapsto v]g}$
  & \textsc{E-AppAbs} \\[4pt]
$\theta.\,t$
  & $\theta.\,g \mid \theta.\,s \mid \theta.\,t{:}t$
  & \\[4pt]
  & $\dfrac{\epsilon[\theta.\,g]}{\lambda x.\ x\ (\lambda y.\,y)\ g}$
  & \textsc{E-Ground} \\[4pt]
  & $\dfrac{\epsilon[\theta.\,s]}{\theta.\,\sigma[s]}$
  & \textsc{E-Separate} \\[4pt]
  & $\dfrac{\epsilon[\theta.\,t_1{:}t_2]}{\lambda x.\ x\ (\theta.\,t_2)\ (\theta.\,t_1)}$
  & \textsc{E-Squash} \\[4pt]
$h$
  & $\dfrac{\epsilon[h]}{h}$
  & \textsc{E-MultiLayer}
\end{tabular*}
\end{minipage}}%
\hfill
\fbox{\begin{minipage}[t]{0.47\textwidth-2\fboxsep-2\fboxrule}
\vspace{0pt}
\small
\begin{tabular*}{\linewidth}{@{}l@{\extracolsep{\fill}}c@{\extracolsep{\fill}}r@{}}
  & \textbf{Separation} & $\sigma[s] \to t$ \\[4pt]
$\lambda x.\,h$
  & $\lambda x.\,s \mid \lambda x.\,p$
  & \\[4pt]
  & $\dfrac{\sigma[\lambda x.\,s]}{\lambda x.\,\sigma[s]}$
  & \textsc{S-Abs} \\[4pt]
  & $\dfrac{\sigma[\lambda x.\,t_1{:}t_2]}{(\lambda x.\,t_1){:}(\lambda x.\,t_2)}$
  & \textsc{S-AbsDist} \\[4pt]
$g\ h$
  & $\dfrac{\sigma[g\ h]}{g{:}g\ h}$
  & \textsc{S-Clone1} \\[4pt]
$h\ g$
  & $\dfrac{\sigma[h\ g]}{h\ g{:}g}$
  & \textsc{S-Clone2} \\[4pt]
$h\ h$
  & $s\ h \mid p\ s \mid p\ p$
  & \\[4pt]
  & $\dfrac{\sigma[s\ h]}{\sigma[s]\ h}$
  & \textsc{S-App1} \\[4pt]
  & $\dfrac{\sigma[p\ s]}{p\ \sigma[s]}$
  & \textsc{S-App2} \\[4pt]
  & $\dfrac{\sigma[t_1{:}t_2\ t_3{:}t_4]}{(t_1\ t_3){:}(t_2\ t_4)}$
  & \textsc{S-AppDist}
\end{tabular*}
\end{minipage}}

\renewcommand{\arraystretch}{1}

\newpage

%% ── Notes ────────────────────────────────────────────────────────────────

\section*{Notes}

\begin{itemize}
\item The Theta-Calculus ($\theta$-calculus) is an extended version of the Lambda-Calculus ($\lambda$-calculus).
\item $\dfrac{a}{a'} \coloneqq a$ evaluates to $a'$, either directly or by forwarding evaluation to a sub-term.
\item Terms are either open or closed (cf.\ Pierce, TAPL 5.1.Scope). A closed term that evaluates to itself is either a value ($v$) or stuck. A closed term is stuck if it is in normal form but not a value (cf.\ Pierce, TAPL 3.5.15). Multi-layer terms ($h$) are stuck under evaluation; they require explicit unlayering via $\theta$ to make progress.
\item Separation is defined only on separable terms ($s$). Single-layer terms ($g$) and already-separated terms ($p$) need no separation, so they are excluded from $\sigma$'s domain.
\item Unlayering ($\theta$) is total: every sub-case produces a new term. There are no stuck cases in unlayering.
\item The squash rule applies $\theta$ recursively to both sub-terms: $\theta.\,t_1{:}t_2 \to \lambda x.\ x\ (\theta.\,t_2)\ (\theta.\,t_1)$. This is necessary because $\theta.\,t$ is classified as a single-layer term ($g$); returning raw $t_1$ or $t_2$ without $\theta$ could yield multi-layer terms ($h$), violating the syntactic category.
\end{itemize}

%% ── Examples ─────────────────────────────────────────────────────────────

\section*{Examples}

\subsection*{Combinators}

$I:= \lambda x. x$

$B:= \lambda f.\lambda g. \lambda x.f\ (g\ x)$

For simplicity, $G$ uses $\text{if}$ clauses and a $\text{TypeError}$ keyword. I also use pseudocode for names such as the predefined types $Int$ and $Str$ for integers and strings, and the addition operator $+$.

$G_a:= \lambda a.\lambda b. \text{if}\  b<:a\text{ then }a\text{ else }\text{TypeError}$

$G$ takes two arguments: $a$, the formal parameter type declared in the function signature, and $b$, the type of the argument actually passed. $G_a$ returns $a$---the declared type---making the type check independent of the argument's type. This is the common case. When the result must depend on the argument's type (e.g.\ resource management), we use $G_b$ instead (see Substructural types below).

\subsection*{Simply Typed Lambda-Calculus (STL) Correspondence}

STL: $\lambda x{:}T.t$

$\theta$-Calculus: $B\ (\lambda x.t)\ (I{:}(G_a\ T))$

Example---increment function:

$(\lambda x{:}Int. x + 1)\ 2$

= $(B\ (\lambda x.x + (1{:}Int))\ (I{:}(G_a\ Int)))\ (2{:}Int)$

By $B\ f\ g\ x = f\ (g\ x)$:

= $(\lambda x.x + (1{:}Int))\ ((I{:}(G_a\ Int))\ (2{:}Int))$

Distribute application over layers ($p\ p$, \textsc{S-AppDist}):

= $(\lambda x.x + (1{:}Int))\ ((I\ 2){:}((G_a\ Int)\ Int))$

$I\ 2 = 2$, and $(G_a\ Int)\ Int = (\lambda b.\ \text{if}\ b<:Int\ \text{then}\ Int\ \text{else}\ \text{TypeError})\ Int = Int$:

= $(\lambda x.x + (1{:}Int))\ (2{:}Int)$

Separate $(\lambda x.x + (1{:}Int))$ (\textsc{S-AbsDist}):

= $((\lambda x.x + 1){:}(\lambda x.x + Int))\ (2{:}Int)$

Distribute application over layers ($p\ p$, \textsc{S-AppDist}):

= $((\lambda x.x + 1)\ 2){:}((\lambda x.x + Int)\ Int)$

= $(2 + 1){:}(Int + Int) = 3{:}Int$

\subsection*{Polymorphic Lambda-Calculus (System F) Correspondence}

System F: $id = \lambda X. \lambda x{:}X. x$

$\theta$-Calculus: $id = \lambda X. B\ (\lambda x. x)\ (I{:}(G_a\ X))$

\subsection*{Substructural Type Correspondence}

$G_b:= \lambda a.\lambda b. \text{if}\  b<:a\text{ then }b\text{ else }\text{TypeError}$

Here the argument type may carry state---for example, whether a file is open or closed.

STL: $\lambda x{:}T.t$

$\theta$-Calculus: $B\ (\lambda x.t)\ (I{:}(G_b\ T))$

\subsection*{Dependent Type Correspondence}

$T_D:= \lambda x. t_d$

$G_D:= \lambda a.\lambda b. \lambda x. G_{a\mid b\mid D}\ (a\ x)\ (b\ x)$

$G_D$ is a delayed dependent type guard. When type checking depends on a value that is not yet available, we wrap the type check in an abstraction ($\lambda x$). The check is then executed later, once the value is supplied.

Dependent type: $\lambda x{:}T_D.t$

$\theta$-Calculus: $B\ (\lambda x.t)\ (I{:}(G_D\ T_D))$

\end{document}
